{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8321c5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17401006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Set up the device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a96161",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSTEDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "\n",
    "        # Walk the directory and gather (image_path, person_id)\n",
    "        for person_id in sorted(os.listdir(root_dir)):\n",
    "            person_folder = os.path.join(root_dir, person_id)\n",
    "            if os.path.isdir(person_folder) and not person_id.startswith(\"cheek\"):\n",
    "                for img_name in sorted(os.listdir(person_folder)):\n",
    "                    if not img_name.endswith(\".mp4\"):  # Only process .jpg files\n",
    "                        img_path = os.path.join(person_folder, img_name)\n",
    "                        self.samples.append((img_path, person_id))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, person_id = self.samples[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        return image, person_id  # You can encode person_id if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6bd89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "mste_e = MSTEDataset(root_dir=\"/Users/sree/mst-e\", transform=transform)\n",
    "mste_e_loader = DataLoader(mste_e, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499e4aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display all images in the mste_e dataset\n",
    "# for idx, (image, label) in enumerate(mste_e):\n",
    "#     plt.figure(figsize=(3, 3))\n",
    "#     plt.imshow(image.permute(1, 2, 0).numpy())  # Convert tensor to numpy array and adjust dimensions\n",
    "#     plt.title(f\"Label: {label}\")\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae25bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
